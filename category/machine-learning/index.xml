<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning | Enrico Meloni</title>
    <link>https://enricomeloni.github.io/category/machine-learning/</link>
      <atom:link href="https://enricomeloni.github.io/category/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Machine Learning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 24 Jun 2020 15:48:01 +0200</lastBuildDate>
    <image>
      <url>https://enricomeloni.github.io/images/icon_huf022ad649bd96409e984953ceb6bb8b9_73364_512x512_fill_lanczos_center_2.png</url>
      <title>Machine Learning</title>
      <link>https://enricomeloni.github.io/category/machine-learning/</link>
    </image>
    
    <item>
      <title>Object Detection with V-DAENY</title>
      <link>https://enricomeloni.github.io/project/daeny/</link>
      <pubDate>Wed, 24 Jun 2020 15:48:01 +0200</pubDate>
      <guid>https://enricomeloni.github.io/project/daeny/</guid>
      <description>&lt;p&gt;Recently, Deep Neural Networks have seen many successful applications, thanks to the huge amount of data that has steadily become more and more available with the growth of the internet. When annotations are not already available, images must be manually annotated introducing costs that can possibly be very high. Furthermore, in some contexts also gathering valuable images could be impractical for reasons related to privacy, copyright and security.
To overcome these limitations the research community has started to take interest in creating virtual environments for the generation of automatically annotated training samples. In previous literature, using a graphics engine for augmenting a training dataset has been proven a valid solution. 
In this work, we applied the virtual environment to approach to a not yet considered task: the detection of personal protection equipment. The first contribution is V-DAENY, a plugin for GTA-V, a famous videogame. V-DAENY allows the creation of scenario with the possibility of customizing most aspects of it: number of people, their equipment and behavior, weather conditions and time of day. With V-DAENY, we automatically generated over 140,000 annotated images in several locations of the game map and with different weather conditions.&lt;/p&gt;
&lt;p&gt;GitHub page: &lt;a href=&#34;https://github.com/enricomeloni/GTA5_Mods&#34;&gt;https://github.com/enricomeloni/GTA5_Mods&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Face Recognition App</title>
      <link>https://enricomeloni.github.io/project/facerecognition/</link>
      <pubDate>Wed, 24 Jun 2020 15:47:45 +0200</pubDate>
      <guid>https://enricomeloni.github.io/project/facerecognition/</guid>
      <description>&lt;p&gt;This Android app performs face recognition and identification through the smartphone&amp;rsquo;s camera. The app uses an internal database containing the known identities, including sample photos. The app allows the user to check the database content, delete or add new identities.&lt;/p&gt;
&lt;p&gt;Face Detection is powered by Haar Cascade Classifier. Face Feature are extracted by VGG2 trained on VGGFace2.&lt;/p&gt;
&lt;p&gt;Classification is performed by weighted kNN on the extracted face features.&lt;/p&gt;
&lt;p&gt;Data processing is powered by OpenCV for Java.&lt;/p&gt;
&lt;p&gt;GitHub page: &lt;a href=&#34;https://github.com/MeloniZippoProjects/MultimediaProject&#34;&gt;https://github.com/MeloniZippoProjects/MultimediaProject&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SAILab Virtual Environmnet</title>
      <link>https://enricomeloni.github.io/project/lve/</link>
      <pubDate>Wed, 24 Jun 2020 15:47:32 +0200</pubDate>
      <guid>https://enricomeloni.github.io/project/lve/</guid>
      <description>&lt;p&gt;SAILab Virtual Environment is a part of the Learning In Visual Environments project at SAILab (&lt;a href=&#34;http://sailab.diism.unisi.it/lve/)&#34;&gt;http://sailab.diism.unisi.it/lve/)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The virtual environment is developed with Unity3D and exposes useful information for training a Visual Agents, including full pixel-wise supervisions, optical flow, and depth for each produced frame. Frames are produced at real-time speed, and are accessible through a Python API designed to easily interface with the most widely adopted Machine Learning frameworks.&lt;/p&gt;
&lt;p&gt;The software and source code will be soon available.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning SIR/SIDARTHE</title>
      <link>https://enricomeloni.github.io/project/covid-tools/</link>
      <pubDate>Wed, 24 Jun 2020 15:47:27 +0200</pubDate>
      <guid>https://enricomeloni.github.io/project/covid-tools/</guid>
      <description>&lt;p&gt;The COVID-19 outbreak has stimulated the interest in the proposal of novel epidemiological models to predict the course of the epidemic so as to help planning effective control strategies. In particular, in order to properly interpret the available data, it has become clear that one must go beyond most classic epidemiological models and consider models that, like the recently proposed SIDARTHE, offer a richer description of the stages of infection. The problem of learning the parameters of these models is of crucial importance especially when assuming that they are time-variant, which further enriches their effectiveness. This project focuses on developing a general approach for learning time-variant parameters of dynamic compartmental models from epidemic data.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
