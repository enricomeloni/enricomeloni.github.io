[{"authors":["admin"],"categories":null,"content":"I am a PhD student in Machine Learning and Explainable AI, at the University of Florence (Smart Computing). I make my research work at SAILab at the University of Siena. My research interests include computer vision, development of virtual environments for training of visual agents. I have a strong passion for Software Engineering and programming.\nYou can also find me at my personal page in SAILaB website.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://enricomeloni.github.io/author/enrico-meloni/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/enrico-meloni/","section":"authors","summary":"I am a PhD student in Machine Learning and Explainable AI, at the University of Florence (Smart Computing). I make my research work at SAILab at the University of Siena. My research interests include computer vision, development of virtual environments for training of visual agents.","tags":null,"title":"Enrico Meloni","type":"authors"},{"authors":["Enrico Meloni"],"categories":null,"content":"","date":1600965000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600965000,"objectID":"cee1a295a5f080dda72bd2cf07134bf6","permalink":"https://enricomeloni.github.io/talk/iaml_covid/","publishdate":"2020-09-16T13:44:49+02:00","relpermalink":"/talk/iaml_covid/","section":"talk","summary":" **Italiano**\n\nL’epidemia di COVID-19 ha stimolato l’interesse in modelli epidemiologici che possano predire l’andamento dell’epidemia e aiutare a pianificare strategie di controllo efficaci. Una delle proposte più recenti è SIDARTHE, un modello che offre una ricca descrizione degli stadi dell’infezione. Imparare i parametri del modello ha una cruciale importanza per permetterci di comprendere come l’epidemia si evolve, specialmente per capire i cambiamenti dovuti agli interventi non farmaceutici, come il lockdown. Mostriamo un approccio generale all’apprendimento di parametri tempo-varianti dei modelli epidemiologici a partire dai dati epidemici. Mostriamo anche un’implementazione in PyTorch di tale approccio e i risultati del processo di apprendimento.\n\n***\n\n**English**\n\nThe COVID-19 outbreak has stimulated the interest in epidemiological models to predict the course of the epidemic and help planning effective control strategies. One of the recent proposals is SIDARTHE, which offers a rich description of the stages on infection. The problem of learning the parameters of the model is of crucial importance to understand the evolution of the epidemic, especially to understand the changes due to non-pharmaceuticals interventions such as lockdowns. We show a general approach to learning time-variant parameters of epidemiological models from epidemic data using. We also show a PyTorch implementation of such approach and the results of the learning process.","tags":["epidemics","covid19","gradient flow","gradient descent","sir","sidarthe","covid"],"title":"Machine Learning for Epidemiological Models","type":"talk"},{"authors":["Enrico Meloni"],"categories":null,"content":"","date":1600246800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600246800,"objectID":"3698009fb362cffecf3cc8d92b3dd03e","permalink":"https://enricomeloni.github.io/talk/sailenv/","publishdate":"2020-09-11T19:37:17+02:00","relpermalink":"/talk/sailenv/","section":"talk","summary":"Recently, researchers in Machine Learning algorithms, Computer Vision scientists, engineers, and others, showed a growing interest in 3D simulators as a mean to artificially create experimental settings that are remarkably close to those in the real world. However, most of the existing platforms to interface algorithms with 3D environments are often designed to setup navigation-related experiments, to study physical interactions, or to handle ad-hoc cases that are not thought to be customized, sometimes lacking a strong photorealistic appearance and an easy-to-use software interface. In this talk, we will present a platform developed in our lab, SAILenv, that is specifically designed to be simple and customizable, and that allows researchers to experiment visual recognition in virtual 3D scenes. A few lines of code are needed to interface every algorithm with the virtual world, and non-3D-graphics experts can easily customize the 3D environment itself, exploiting a collection of photorealistic objects. Our framework yields pixel-level semantic and instance labeling, depth, and, to the best of our knowledge, it is the only one that provides motion-related information directly inherited from the 3D engine. The client-server communication operates at a low level, avoiding the overhead of HTTP-based data exchanges. We perform experiments using a state-of-the-art object detector trained on real-world images, showing that it is able to recognize the photorealistic 3D objects of our environment. The computational burden of the optical flow compares favorably with the estimation performed using modern GPU-based convolutional networks or more classic implementations.","tags":["computer vision","virtual environments","visual agents","unity3D"],"title":"SAILenv: Learning in Virtual VisualEnvironments Made Simple","type":"talk"},{"authors":["Enrico Meloni"],"categories":["Software Development"],"content":"Triple Triad is a Collectable Card Game which made its debut in Final Fantasy 8. This is a remake in form of a webapp with vanilla javascript and html.\nThis webapp was developed for a university project and while the games are playable, there is no artificial intelligence that makes a game worth playing.\n","date":1593193607,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593193607,"objectID":"c8affc70896a85c3afda6974e298050d","permalink":"https://enricomeloni.github.io/project/tripletriadworld/","publishdate":"2020-06-26T19:46:47+02:00","relpermalink":"/project/tripletriadworld/","section":"project","summary":"A triple triad webapp in Javascript and HTML","tags":["triple triad","final fantasy 8","games"],"title":"Triple Triad World","type":"project"},{"authors":["Enrico Meloni","Marco Di Benedetto","Giuseppe Amato","Fabrizio Falchi","Claudio Gennaro"],"categories":["Machine Learning"],"content":"Recently, Deep Neural Networks have seen many successful applications, thanks to the huge amount of data that has steadily become more and more available with the growth of the internet. When annotations are not already available, images must be manually annotated introducing costs that can possibly be very high. Furthermore, in some contexts also gathering valuable images could be impractical for reasons related to privacy, copyright and security. To overcome these limitations the research community has started to take interest in creating virtual environments for the generation of automatically annotated training samples. In previous literature, using a graphics engine for augmenting a training dataset has been proven a valid solution. In this work, we applied the virtual environment to approach to a not yet considered task: the detection of personal protection equipment. The first contribution is V-DAENY, a plugin for GTA-V, a famous videogame. V-DAENY allows the creation of scenario with the possibility of customizing most aspects of it: number of people, their equipment and behavior, weather conditions and time of day. With V-DAENY, we automatically generated over 140,000 annotated images in several locations of the game map and with different weather conditions.\n","date":1593006481,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593006481,"objectID":"4552ccaa960989401f27d46d4a2c98e0","permalink":"https://enricomeloni.github.io/project/daeny/","publishdate":"2020-06-24T15:48:01+02:00","relpermalink":"/project/daeny/","section":"project","summary":"A Dataset Generator powered by a modded version of GTA V","tags":["virtual environments","computer vision","gta5","c#","YOLO","machine learning","object detection"],"title":"Object Detection with V-DAENY","type":"project"},{"authors":["Enrico Meloni","Raffaele Zippo"],"categories":["Machine Learning"],"content":"This Android app performs face recognition and identification through the smartphone\u0026rsquo;s camera. The app uses an internal database containing the known identities, including sample photos. The app allows the user to check the database content, delete or add new identities.\nFace Detection is powered by Haar Cascade Classifier. Face Feature are extracted by VGG2 trained on VGGFace2.\nClassification is performed by weighted kNN on the extracted face features.\nData processing is powered by OpenCV for Java.\n","date":1593006465,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593006465,"objectID":"306c5653afd984377435463a84a7b0d7","permalink":"https://enricomeloni.github.io/project/facerecognition/","publishdate":"2020-06-24T15:47:45+02:00","relpermalink":"/project/facerecognition/","section":"project","summary":"A face recognition app for android powered by Machine Learning","tags":["machine learning","android","app","java","face recognition"],"title":"Face Recognition App","type":"project"},{"authors":["Enrico Meloni","Raffaele Zippo","Marco Pinna"],"categories":["Software Development"],"content":"WARNING: This is an ongoing project Experiment Launcher (temporary name) is a scientific utility aimed at storing the experimental results out-putted by a third party software. It allows the user to specify an experiment with a set of parameters andan executable file, and then proceeds to launch the executable and collecting the output. The output is then provided to the user in a human-friendly interface, recording important information such as the date and timewhen the experiment was launched, the parameters, and also the executable version (if version control is used).\n","date":1593006458,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593006458,"objectID":"1115e33f2c7ccb3d78e034e191f8eb10","permalink":"https://enricomeloni.github.io/project/explauncher/","publishdate":"2020-06-24T15:47:38+02:00","relpermalink":"/project/explauncher/","section":"project","summary":"An Electron app for managing and launching batch of experiments","tags":["typescript","electron","experiments","data analysis","data visualization"],"title":"Exp Launcher","type":"project"},{"authors":["Enrico Meloni","Luca Pasqualini","Matteo Tiezzi","Marco Gori","Stefano Melacci"],"categories":["Machine Learning"],"content":"SAILenv is a Virtual Environment powered by Unity3D. It includes 3 pre-built scenes with full pixel-wise annotations. SAILenv is capable of generating frames at real-time speed, complete with pixel-wise annotations, optical flow and depth.\nSAILenv also comes with a Python API, designed to easily integrate with the most common learning frameworks available.\nSAILenv is a running project at SAILab. More information is available at the project page. Source code and executables are also available there.\n","date":1593006452,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593006452,"objectID":"2177187db5abd232f37554274a6d6133","permalink":"https://enricomeloni.github.io/project/lve/","publishdate":"2020-06-24T15:47:32+02:00","relpermalink":"/project/lve/","section":"project","summary":"A virtual environment for generating fully annotated video streams.","tags":["machine learning","virtual environments","computer vision","c#","unity3d"],"title":"SAILenv","type":"project"},{"authors":["Enrico Meloni"],"categories":["Machine Learning"],"content":"The COVID-19 outbreak has stimulated the interest in the proposal of novel epidemiological models to predict the course of the epidemic so as to help planning effective control strategies. In particular, in order to properly interpret the available data, it has become clear that one must go beyond most classic epidemiological models and consider models that, like the recently proposed SIDARTHE, offer a richer description of the stages of infection. The problem of learning the parameters of these models is of crucial importance especially when assuming that they are time-variant, which further enriches their effectiveness. This project focuses on developing a general approach for learning time-variant parameters of dynamic compartmental models from epidemic data.\n","date":1593006447,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593006447,"objectID":"3c1b55eac976a857445a4bd29ed55fc2","permalink":"https://enricomeloni.github.io/project/covid-tools/","publishdate":"2020-06-24T15:47:27+02:00","relpermalink":"/project/covid-tools/","section":"project","summary":"Learning the epidemiological parameters of COVID-19 through Machine Learning.","tags":["sir","sidarthe","machine learning","pytorch","dynamic systems"],"title":"Learning SIR/SIDARTHE","type":"project"},{"authors":["Enrico Meloni","Raffaele Zippo","Edoardo Sassu","Giuseppe Lettieri","Richard Barger"],"categories":["Software Development"],"content":"WanRaptor is my first job as a Software Engineer and Project Manager with a big enterprise.\nThe WanRaptor is an embedded system used to validate an application in a lab environment by emulating bandwidth limitations, latency, packets loss and jitter commonly found in WANs.\nThe project involved the development from the ground up of the full-stack Graphical User Interface, including management of hardware resources, installation, secure licensing and user interaction.\nThe WanRaptor is widely used in many laboratories all over United States and further.\n","date":1593006428,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593006428,"objectID":"34f891b4ff47cef5c4162e30a9eb5526","permalink":"https://enricomeloni.github.io/project/wanraptor/","publishdate":"2020-06-24T15:47:08+02:00","relpermalink":"/project/wanraptor/","section":"project","summary":"An embedded Network Impairments Emulator with high-bandwidth and high precision performances","tags":["wanraptor","java","grails","typescript","javascript","node","embedded systems","network emulator"],"title":"WanRaptor","type":"project"},{"authors":["Enrico Meloni","Giovanni Cignoni"],"categories":["Software Development"],"content":"Validation, correction and extension of CHKB, an encyclopedic web app which main objective is to bring together all informations about computers and more generally about information science history.\n","date":1593006425,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593006425,"objectID":"b0cf44449e80ef057183abe29e1a6786","permalink":"https://enricomeloni.github.io/project/chkb/","publishdate":"2020-06-24T15:47:05+02:00","relpermalink":"/project/chkb/","section":"project","summary":"Encyclopedic Web App to catalog Computer History.","tags":["chkb","computer history","software engineering","php"],"title":"CHKB","type":"project"},{"authors":["Enrico Meloni","Raffaele Zippo"],"categories":["Software Development"],"content":"This library was developed as group project for Concurrent and Distributed Systems course.\nThe idea behind this project was to implement first-hand a synchronization layer like most multiplayer games use nowadays. The simulation (game) in object is collaborative effort where multiple clients generate inputs that drive it. The synchronization layer has to guarantee that each client processes inputs in the correct order so that everyone has a consistent view of the simulation, without ever sharing its state directly.\nWe chose to implement the most strict version of lockstep, which doesn\u0026rsquo;t allow for the simulation to go on speculatively in case of delays, contrary to most games. We also chose the client-server structure, which should give the lowest delay in most cases. In order to make the library as generic as possible, we chose to use Java Serialization for marshalling/unmarshalling. This gives a huge overhead in terms of bandwidth, and should be reconsidered given the specific application needs.\n\r\rClient Structure\r\r\r\r\rServer Structure\r\r\r","date":1593006417,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593006417,"objectID":"3586e3c94815dae86f2c01ce9d2294e4","permalink":"https://enricomeloni.github.io/project/lockstep-library/","publishdate":"2020-06-24T15:46:57+02:00","relpermalink":"/project/lockstep-library/","section":"project","summary":"A Lockstep Network Synchronization Layer for distributed reliable simulations","tags":["java","concurrent systems","distributed systems","distributed simulations","lockstep"],"title":"Lockstep Library","type":"project"},{"authors":["Enrico Meloni","Raffaele Zippo"],"categories":["Software Development"],"content":"The application is a secure photo sharing service which uses KPABE encryption to enforce access to pictures exclusively to allowed users. The application is written in C# for the Windows platform and depends on a KPABE command line implementation\n(*): The featured image is extracted from A Work in Progress: Context based Encryption Scheme for Internet of Things\n","date":1593006408,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593006408,"objectID":"ad1e0b66ba615b3db9a3690aeb1d6465","permalink":"https://enricomeloni.github.io/project/abe-photo-sharing/","publishdate":"2020-06-24T15:46:48+02:00","relpermalink":"/project/abe-photo-sharing/","section":"project","summary":"Secure Photo Sharing Service powered by KPABE","tags":["security","kpabe","encryption","c#","windows"],"title":"ABE Photo Sharing","type":"project"},{"authors":["Enrico Meloni"],"categories":null,"content":"","date":1589364004,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589364004,"objectID":"ae31bedbcd9ee93510dc61894aa8d5a4","permalink":"https://enricomeloni.github.io/talk/dynamic_sir/","publishdate":"2020-06-24T15:21:04+02:00","relpermalink":"/talk/dynamic_sir/","section":"talk","summary":"The problem of parameter estimation for an epidemic model is crucial for the forecasting of the infection spread. We discuss an approach for learning the time-variant parameters of the dynamic SIR model from data. We formulate the problem in terms of a functional risk that depends on the learning variables through the solutions of the dynamic SIR. The resulting variational problem is then solved using a gradient flow on a suitable, regularized, functional.","tags":["epidemics","covid19","gradient flow","gradient descent","sir"],"title":"Learning the Dynamic SIR Model: An Optimal Control Approach","type":"talk"},{"authors":["Marco Di Benedetto","Fabio Carrara","Enrico Meloni","Giuseppe Amato","Fabrizio Falchi","Claudio Gennaro"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"19bcaf381b078046daf266bd67484a02","permalink":"https://enricomeloni.github.io/publication/di-2020-learning/","publishdate":"2020-08-29T11:34:43.065362Z","relpermalink":"/publication/di-2020-learning/","section":"publication","summary":"Deep learning has achieved impressive results in many machine learning tasks such as image recognition and computer vision. Its applicability to supervised problems is however constrained by the availability of high-quality training data consisting of large numbers of humans annotated examples (e.g. millions). To overcome this problem, recently, the AI world is increasingly exploiting artificially generated images or video sequences using realistic photo rendering engines such as those used in entertainment applications. In this way, large sets of training images can be easily created to train deep learning algorithms. In this paper, we generated photo-realistic synthetic image sets to train deep learning models to recognize the correct use of personal safety equipment (e.g., worker safety helmets, high visibility vests, ear protection devices) during at-risk work activities. Then, we performed the adaptation of the domain to real-world images using a very small set of real-world images. We demonstrated that training with the synthetic training set generated and the use of the domain adaptation phase is an effective solution for applications where no training set is available.","tags":null,"title":"Learning accurate personal protective equipment detection from virtual worlds","type":"publication"},{"authors":["Enrico Meloni","Luca Pasqualini","Matteo Tiezzi","Marco Gori","Stefano Melacci"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"9029590ccfca63079f30c8ecc8b3afa9","permalink":"https://enricomeloni.github.io/publication/meloni-2020-sailenv/","publishdate":"2020-07-17T09:35:08.855332Z","relpermalink":"/publication/meloni-2020-sailenv/","section":"publication","summary":"Recently, researchers in Machine Learning algorithms, Computer Vision scientists, engineers and others, showed a growing interest in 3D simulators as a mean to artificially create experimental settings that are very close to those in the real world. However, most of the existing platforms to interface algorithms with 3D environments are often designed to setup navigation-related experiments, to study physical interactions, or to handle ad-hoc cases that are not thought to be customized, sometimes lacking a strong photorealistic appearance and an easy-to-use software interface. In this paper, we present a novel platform, SAILenv, that is specifically designed to be simple and customizable, and that allows researchers to experiment visual recognition in virtual 3D scenes. A few lines of code are needed to interface every algorithm with the virtual world, and non-3D-graphics experts can easily customize the 3D environment itself, exploiting a collection of photorealistic objects. Our framework yields pixel-level semantic and instance labeling, depth, and, to the best of our knowledge, it is the only one that provides motion-related information directly inherited from the 3D engine. The client-server communication operates at a low level, avoiding the overhead of HTTP-based data exchanges. We perform experiments using a state-of-the-art object detector trained on real-world images, showing that it is able to recognize the photorealistic 3D objects of our environment. The computational burden of the optical flow compares favourably with the estimation performed using modern GPU-based convolutional networks or more classic implementations. We believe that the scientific community will benefit from the easiness and high-quality of our framework to evaluate newly proposed algorithms in their own customized realistic conditions.","tags":null,"title":"SAILenv: Learning in Virtual Visual Environments Made Simple (pre-print)","type":"publication"},{"authors":["Enrico Meloni"],"categories":null,"content":"","date":1574848800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574848800,"objectID":"9b09a5b92757639cdab7afec71affd12","permalink":"https://enricomeloni.github.io/talk/lve/","publishdate":"2020-06-24T15:21:42+02:00","relpermalink":"/talk/lve/","section":"talk","summary":"Recently, there have been many breakthroughs in computer vision thanks to Deep Learning. The availability of huge annotated datasets was one of the reasons of this success, if not the most important. However, these datasets have usually been static datasets, with little to no possibility of interaction with the learning agent. Interaction with the environment is critical if one desires to learn in a human-like fashion. Since placing a learning agent in a real environment could be dangerous to things and people, a promising solution is to use Virtual Environments: 3D graphics engines that can simulate real-like scenarios, allowing some degrees of interaction with the environment.\nIn this seminar, we review some of the available Virtual Environments: RAGE, the graphics engine for videogames such as GTA; Habitat AI, a large-scale scenarios Virtual Environment developed by Facebook AI; AI2-Thor, a Virtual Environment with interaction at its core; finally, we explore the pros and cons of building a custom Virtual Environment.","tags":["computer vision","virtual environments","visual agents","unity3D"],"title":"Learning in Virtual Environments","type":"talk"},{"authors":["Marco Di Benedetto","Enrico Meloni","Giuseppe Amato","Fabrizio Falchi","Claudio Gennaro"],"categories":null,"content":" Awarded Best Paper at CBMI 2019  ","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"3d5fc965ffc11b5f2478e2e83765041c","permalink":"https://enricomeloni.github.io/publication/di-benedetto-learning-2019/","publishdate":"2020-06-24T13:14:33.260084Z","relpermalink":"/publication/di-benedetto-learning-2019/","section":"publication","summary":"Nowadays, the possibilities offered by state-of-the-art deep neural networks allow the creation of systems capable of recognizing and indexing visual content with very high accuracy. Performance of these systems relies on the availability of high quality training sets, containing a large number of examples (e.g. million), in addition to the the machine learning tools themselves.\n\nFor several applications, very good training sets can be obtained, for example, crawling (noisily) annotated images from the internet, or by analyzing user interaction (e.g.: on social networks). However, there are several applications for which high quality training sets are not easy to be obtained/created. Consider, as an example, a security scenario where one wants to automatically detect rarely occurring threatening events.\n\nIn this respect, recently, researchers investigated the possibility of using a visual virtual environment, capable of artificially generating controllable and photo-realistic contents, to create training sets for applications with little available training images.\n\nWe explored this idea to generate synthetic photo-realistic training sets to train classifiers to recognize the proper use of individual safety equipment (e.g.: worker protection helmets, high-visibility vests, ear protection devices) during risky human activities. Then, we performed domain adaptation to real images by using a very small image data set of real-world photographs.\n\nWe show that training with the generated synthetic training set and using the domain adaptation step is an effective solution to address applications for which no training sets exist. ","tags":null,"title":"Learning safety equipment detection using virtual worlds","type":"publication"},{"authors":["Enrico Meloni"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"ca3c30d0dfbf3abbaa6b4881e2d4834e","permalink":"https://enricomeloni.github.io/publication/meloni-using-2019/","publishdate":"2020-06-24T13:14:33.259083Z","relpermalink":"/publication/meloni-using-2019/","section":"publication","summary":"Neural Networks are known to be an effective technique in the field of Artificial Intelligence and in particular in the field of Computer Vision. Their main advantage is that they can learn from examples, without the need to program into them any previous expertise or knowledge.\n\nRecently, Deep Neural Networks have seen many successful applications, thanks to the huge amount of data that has steadily become more and more available with the growth of the internet. When annotations are not already available, images must be manually annotated introducing costs that can possibly be very high. Furthermore, in some contexts also gathering valuable images could be impractical for reasons related to privacy, copyright and security.\n\nTo overcome these limitations the research community has started to take interest in creating virtual environments for the generation of automatically annotated training samples. In previous literature, using a graphics engine for augmenting a training dataset has been proven a valid solution.\n\nIn this work, we applied the virtual environment to approach to a not yet considered task: the detection of personal protection equipment. The first contribution is  V-DAENY, a plugin for GTA-V, a famous videogame. V-DAENY allows the creation of scenario with the possibility of customizing most aspects of it: number of people, their equipment and behavior, weather conditions and time of day. With V-DAENY, we automatically generated over 140,000 annotated images in several locations of the game map and with different weather conditions.\n\nThe second contribution are two different datasets composed of real images, that can be used for training and testing. One of them contains images with copyright limits, while the second contains only copyright free images. Both datasets contain pictures taken in various contexts, such as airports, building sites and military sites.\n\nThe third contribution is the evaluation of the performances achieved by learning with virtual data. We trained a network starting from a pre-trained YOLOv3 detector and applying a phase of Transfer Learning with virtual data and a phase of Domain Adaptation with a small amount of the manually annotated real dataset. Then, we tested the network on the other part of the real dataset. The network trained with this approach achieves promising performances. After being trained with only virtual data, the network achieves excellent precision on virtual data and good precision on real data. After applying Domain Adaptation, the network achieves high precision on both real and virtual data. As comparison, applying only Domain Adaptation to base YOLOv3 achieves a precision similar to that obtained when training with only virtual data. These results suggest that computer generated training samples can replace most of the real dataset and still achieve very good results. ","tags":null,"title":"Using virtual worlds to train an object detector for personal protection equipment","type":"publication"}]